---
title: "Sprawozdanie 2. Grupa 3. Testowanie hipotez statystycznych"
author: "Emil Olszewski, Jakub Kempa"
format: pdf
editor: visual
---

# 1. Wprowadzenie

Będziemy testować hipotezy statystyczne na poziomie istotności $\alpha = 0.05$. Przestestujemy hipotezę

$$
 H_0: \mu = 1
$$

przeciwko

$$
H_1: \mu \ne 1
$$

Wykorzystamy następujące testy:

-   **test z** przy założeniu $\sigma = 2$

-   **test t-Studenta**

-   **test rang znakowanych Wilcoxona**

```{r}
#| echo: false
#| warning: false
library(tidyverse)
library(stats)
```

## 1.1 Wstęp do hipotezy zerowej

\
Testowanie hipotezy statystycznej $H_0: \mu = 1$ na poziomie istotności $\alpha = 0.05$, to procedura, która ma na celu ocenę czy średnia wartość z analizowanych danych $\mu$ różni się od przyjętej wartości $1$. Poziom istotności $\alpha = 0.05$ oznacza, że jesteśmy w stanie zaakceptować $5\%$ ryzyko, że popełnimy błąd pierwszego rodzaju. Rozróżnia się dwa takie błędy:

-   Błąd pierwszego rodzaju - fałszywe odrzucenie hipotezy zerowej\
    Wiąże się on z nieprawidłowym odrzuceniem hipotezy mówiącej w naszym przypadku o tym, że średnia jest równa 1

-   Błąd drugiego rodzaju - fałszywe zaakceptowanie hipotezy zerowej\
    W tym przypadku nie odrzucamy hipotezy zerowej, mimo że powinniśmy

Badając hipotezę zerową będziemy korzystali z wyżej wymienionych testów. Procedura prezentuje się następująco:

1.  Generujemy 100 wartości z zadanego rozkładu.

2.  Przeprowadzamy testy statystyczne dla wygenerowanego zestawu danych.

3.  Liczymy empiryczną moc testu (prawdopodobieństwo odrzucenia hipotezy zerowej).

4.  Powtarzamy kroki 1. - 3. $MC = 1000$ razy.

5.  Rysujemy wykres funkcji mocy w zależności od $\mu$ na zadanym przedziale.

## 1.2 Teoria

Moc testu statystycznego mierzy jego zdolność do wykrywania rzeczywistego efektu lub różnicy, gdy istnieje. Jest to w zasadzie prawdopodobieństwo poprawnego odrzucenia fałszywej hipotezy zerowej. Kilka czynników wpływa na moc testu:

1.  **Wielkość efektu**: Wielkość różnicy lub efektu, który jest testowany. Większe efekty są łatwiejsze do wykrycia i prowadzą do większej mocy.

2.  **Wielkość próby**: Liczba obserwacji lub uczestników badania. Większe próby zazwyczaj prowadzą do większej mocy, ponieważ dostarczają więcej informacji i zmniejszają efekty losowej zmienności.

3.  **Poziom istotności (**$\alpha$): Próg określający istotność statystyczną. Obniżenie poziomu istotności zmniejsza prawdopodobieństwo popełnienia błędu pierwszego rodzaju (fałszywy wynik pozytywny), ale również zmniejsza moc testu.

4.  **Zmiennosć lub odchylenie standardowe**: Stopień rozrzutu danych. Testy są bardziej efektywne, gdy zmienność jest mniejsza.

5.  **Typ testu**: Różne testy statystyczne mają różne właściwości mocy. Wybór odpowiedniego testu dla pytania badawczego może wpłynąć na moc analizy.

6.  **Założenia**: Naruszenie założeń testu statystycznego może zmniejszyć jego moc. Zapewnienie, że dane spełniają założenia wybranego testu, może pomóc maksymalizować moc.

Ogólnie rzecz biorąc, maksymalizacja mocy polega na równoważeniu tych czynników w celu uzyskania testu wystarczająco wrażliwego do wykrycia istotnych efektów, jednocześnie kontrolując błędy pierwszego i drugiego rodzaju.

```{r}
#| echo: false 

## STATYSTKI 

# Test Z 
stat_z <- function(xs, mu, sigma) {
  # Statystyka ta ma rozkład N(0, 1) przy założeniu hipotezy zerowej
  zstat <- sqrt(length(xs)) * (mean(xs) - mu) / sigma
  return(zstat)
}

# Test t-Studenta
stat_student <- function(xs, mu) {
  # Statystyka ta ma rozkład T(length(xs) - 1) przy założeniu hipotezy zerowej
  tstat <- sqrt(length(xs)) * (mean(xs) - mu) / sd(xs)
  return(tstat)
}

# Test rang znakowanych Wilcoxona
stat_wilcoxon <- function(xs, mu) {
  
  diffs <- xs - mu
  ranks <- rank(abs(diffs))
  
  sum_pos <- sum(ranks[diffs > 0])
  sum_neg <- sum(ranks[diffs < 0])
  
  # Rozkład tej statystyki jest znany (przy założeniu hipotezy zerowej jest on asymptotycznie normalny)
  ustat <- min(sum_pos, sum_neg)
  return(ustat)
}
```

```{r}
#| echo: false 

## TESTY 

testinfo <- function(stat, pval, resu) {
  return(list(
    statystyka = stat,
    pwartosc   = pval,
    wynik      = resu
  ))
}

# Test Z 

ztest <- function(xs, mu, alpha=0.05) {
  
  z <- stat_z(xs, mu, 2) 
  
  lower_q <- qnorm(alpha/2)
  upper_q <- qnorm(1 - alpha/2)
  
  result <- (lower_q <= z && z <= upper_q)
  p_value <- 2 * pnorm(abs(z), lower.tail = FALSE)
  
  
  return(testinfo(z, p_value, result))
  
}

# Test t-Studenta 

ttest <- function(xs, mu, alpha=0.05) {
  
  t <- stat_student(xs, mu)
  df <- length(xs) - 1
  
  lower_q <- qt(alpha/2, df)
  upper_q <- qt(1 - alpha/2, df)
  
  result <- (lower_q <= t && t <= upper_q)
  p_value <- 2 * pt(abs(t), df, lower.tail = FALSE)
  
  return(testinfo(t, p_value, result))
}

# Test znakowanych rang Wilcoxona 

wtest <- function(xs, mu, alpha=0.05) {
  
  w <- stat_wilcoxon(xs, mu)
  n <- length(xs)
  
  lower_q <- qsignrank(alpha/2, n)
  upper_q <- qsignrank(1 - alpha/2, n)
  
  result <- (lower_q <= w && w <= upper_q)
  p_value <- min(2 * psignrank(w-1, n, lower.tail=FALSE, 1))
  
  return(testinfo(w, p_value, result))
}

```

```{r}
#| echo: false

## WYKRESY FUNKCJI MOCY
plot_test_power <- function(dist, n, param, inter, MCS=100) {
  
  gensample <- if (dist == "norm") {
    function(mu) {
      return(rnorm(n, mu, param))
    }
  } else {
    function(lambda) {
      return(rexp(n, 1/lambda))
    }
  }

  ilen = length(inter)
  
  z_power <- numeric(ilen)
  t_power <- numeric(ilen)
  w_power <- numeric(ilen)
  
  for (i in seq_along(inter)) {
    
    mu = inter[i]
    
    z_correct <- MCS
    t_correct <- MCS
    w_correct <- MCS
    
    for (j in seq_len(MCS)) {
      sample <- gensample(mu)
      z_correct = z_correct - ztest(sample, 1)$wynik
      t_correct = t_correct - ttest(sample, 1)$wynik
      w_correct = w_correct - wtest(sample, 1)$wynik
    }
    
    z_power[i] = z_correct / MCS
    t_power[i] = t_correct / MCS
    w_power[i] = w_correct / MCS
    
    
  }
  
  values <- data.frame(
    mu = inter, 
    z = z_power, 
    t = t_power, 
    w = w_power
  )
  
  df_long <- tidyr::gather(values, key = "variable", value = "value", -mu)

  # Plot each column against mu
  ggplot(df_long, aes(x = mu, y = value, color = variable)) +
    geom_line() +
    labs(x = "mu", y = "Value", title = "Plot of z, t, w vs. mu") +
    scale_color_manual(values = c("z" = "blue", "t" = "green", "w" = "red"))  
}

```

# 2. Zadanie 1.

Treść zadania: *Rozważmy próbę* $(X_1, ..., X_{100})$ *z rozkładu normalnego* $\mathcal{N}(\mu, 2^2)$*. Korzystając z symulacji Monte Carlo wykonaj wykres funkcji mocy w zależności od* $\mu$ *na przedziale* $(−1, 3)$ *dla wszystkich trzech testów. Czy istnieje test jednostajnie najmocniejszy spośród nich?*

Zatem, tak jak wspomniane w sekcji 1.1

1.  Generujemy 100 wartości z rozkładu normalnego $\mathcal{N} \sim (\mu, 2^2)$

2.  Przeprowadzamy testy statystyczne dla wygenerowanego zestawu danych.

3.  Liczymy empiryczną moc testu (prawdopodobieństwo odrzucenia hipotezy zerowej).

4.  Powtarzamy kroki 1. - 3. $MC = 1000$ razy.

5.  Rysujemy wykres funkcji mocy w zależności od $\mu$ na przedziale $(-1,3)$.

Wykres prezentuje się następująco:

```{r}
plot_test_power("norm", 100, 2, seq(-1, 3, length.out=50), MCS=1000)
```

Jak widzimy wykresy wszystkich trzech testów pokrywają się ze sobą. Sugeruje to, że wszystkie trzy testy mają podobne możliwości wykrywania prawdziwego efektu lub różnicy. Może to oznaczać, że każdy z testów jest równie odpowiedni dla danego scenariusza i że ich wyniki są porównywalne pod względem mocy statystycznej. Zatem z podanych parametrów nie istnieje test jednostajnie najmocniejszy spośród nich.

# 3. Zadanie 2.

Treść zadania: *Rozważmy próbę* $(X_1, ..., X_{100})$ *z rozkładu normalnego* $\mathcal{N}(\mu, 4^2)$*. Wykonaj wykres funkcji mocy na wybranym przedziale zawierającym przynajmniej po jednym punkcie z hipotezy zerowej i alternatywnej. Jak zmieniła się funkcja mocy testów? Czy w tym przypadku istnieje test jednostajnie najmocniejszy spośród nich?*

Zatem:

1.  Generujemy 100 wartości z rozkładu normalnego $\mathcal{N}(\mu, 2^2)$

2.  Przeprowadzamy testy statystyczne dla wygenerowanego zestawu danych.

3.  Liczymy empiryczną moc testu (prawdopodobieństwo odrzucenia hipotezy zerowej).

4.  Powtarzamy kroki 1. - 3. $MC = 1000$ razy.

5.  Rysujemy wykres funkcji mocy w zależności od $\mu$ na wybranym przez nas przedziale (ponownie rozważamy przedział $(-1,3)$).

Wykres prezentuje się następująco:

```{r}
plot_test_power("norm", 100, 4, seq(-1, 3, length.out=50), MCS=1000)
```

Funkcje mocy testów zmieniły się:

-   Wykresy funkcji mocy testu z oraz testu rang znakowanych Wilcoxona ponownie są do siebie bardzo zbliżone, co ponownie sugeruje podobne możliwości wykrywania prawdziwego efektu lub różnicy.

-   Wykres funkcji mocy testu t-studenta odbiega od funkcji mocy pozostałych dwóch testów. Jego wygląd sugeruje, że moc testu t-studenta jest większa od pozostałych dwóch testów dla zadanych parametrów; test w większą skutecznością jest w stanie wykryć fałszywą hipotezę zerową, niż pozostałe dwa testy.

Na bazie wyglądu wykresów funkcji mocy testów możemy stwierdzić, że w tym przypadku testem jednostajnie najmocniejszym będzie test rang znakowanych wilsona *z*

# 4. Zadanie 3.

Treść zadania: *Rozważmy próbę* $(X_1, ..., X_{100})$ *z rozkładu wykładniczego* $\mathcal{E}(\frac{1}{\mu})$*. Wykonaj wykres funkcji mocy na wybranym przedziale zawierającym przynajmniej po jednym punkcie z hipotezy zerowej i alternatywnej. Jak zmieniła się funkcja mocy testów? Czy w tym przypadku istnieje test jednostajnie najmocniejszy spośród nich?*

Zatem:

1.  Generujemy 100 wartości z rozkładu normalnego $\mathcal{E}(\frac{1}{\mu})$

2.  Przeprowadzamy testy statystyczne dla wygenerowanego zestawu danych.

3.  Liczymy empiryczną moc testu (prawdopodobieństwo odrzucenia hipotezy zerowej).

4.  Powtarzamy kroki 1. - 3. $MC = 1000$ razy.

5.  Rysujemy wykres funkcji mocy w zależności od $\mu$ na przedziale $(0,2)$.

Wykres prezentuje się następująco:

```{r}
plot_test_power("exp", 100, NULL, seq(0, 2, length.out=50), MCS=1000)
```

Ponownie patrzymy na zachowanie funkcji dla $\mu = \mu_0$, przy czym $\mu_0 = 1$. Dla takich parametrów widzimy trzy różne wyniki:

-   Najmocniejszym testem do testowania hipotezy zerowej jest test rang znakowanych Wilcoxona, gdyż dla $\mu = \mu_0$ osiąga on największą wartość. Ten sam test jest jednak narażony na duży poziom błędów I-go rodzaju.

-   Test t-studenta jest słabszy, niż test rang znakowanych Wilcoxona dla testowania hipotezy zerowej, jednak ma ze wszystkich trzech testów najniższy poziom błędów I-go rodzaju.

-   Test z to najsłabszy z testów dla podanych parametrów: Niska moc testu dla $\mu=\mu_0$ oraz większy, niż dla t-studenta poziom błędów I-go rodzaju sugeruje niską użyteczność dla danych o zakładanych parametrach.

Spośród tych testów nie ma jednak testu jednostajnie najmocniejszego.
